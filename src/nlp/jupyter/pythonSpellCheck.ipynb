{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f43f92d",
   "metadata": {},
   "source": [
    "# Spelling Check in Python\n",
    "This notebook demonstrates the use of Python packages to do spelling check/autocorrect. These packages include:\n",
    " - `contextualSpellCheck`\n",
    " - `autocorrect`\n",
    " - `textblob`\n",
    " \n",
    "Each of these packages can be pip installed via:\n",
    " - `pip install contextualSpellCheck`\n",
    " - `pip install autocorrect`\n",
    " - `pip install textblob`\n",
    "     - `textblob` requires the additional code: `python -m textblob.download_corpora` (worked on INL network for me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee0133",
   "metadata": {},
   "source": [
    "## contextualSpellCheck\n",
    "This package is used with spaCy in a spaCy pipeline. The focus is on Out of Vocabulary word or non-word error correction using the BERT model. It attempts to use the context when correcting spelling errors. It looks like there is development activity on this package.\n",
    "\n",
    "There are two ways of including `contextualSpellCheck` in a spaCy pipeline. This package can check spelling, however, an additional step needs to be performed if the tokens should reflect the spell checking.\n",
    "\n",
    "See also:\n",
    "\n",
    "https://github.com/R1j1t/contextualSpellCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf887c",
   "metadata": {},
   "source": [
    "### Load contextualSpellCheck in a spaCy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecb6bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp.pipe_names before adding contextualSpellCheck: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "\n",
      "nlp.pipe_names after  adding contextualSpellCheck: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'contextual spellchecker']\n",
      "\n",
      "contextualSpellCheck added as extension: True\n",
      "\n",
      "spell check performed: True\n",
      "\n",
      "suggestions: {milion: 'million', milion: 'million'}\n",
      "\n",
      "spell check output (str): Income was $9.4 million compared to the prior year of $2.7 million\n",
      "\n",
      "spell check score: {milion: [('million', 0.42275), (',', 0.23874), ('mi', 0.13952), ('billion', 0.10526), ('trillion', 0.01076), ('%', 0.00577), ('Mi', 0.00542), ('##M', 0.00512), ('.', 0.00276), ('Million', 0.00268)], milion: [('.', 0.99228), (';', 0.00648), ('!', 0.00054), ('million', 0.0003), ('billion', 0.00014), ('?', 5e-05), ('...', 2e-05), ('|', 2e-05), ('%', 1e-05), (',', 1e-05)]}\n",
      "\n",
      "Tokens from spacy doc:\n",
      "    Income\n",
      "    was\n",
      "    $\n",
      "    9.4\n",
      "    milion\n",
      "    compared\n",
      "    to\n",
      "    the\n",
      "    prior\n",
      "    year\n",
      "    of\n",
      "    $\n",
      "    2.7\n",
      "    milion\n"
     ]
    }
   ],
   "source": [
    "import contextualSpellCheck\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(f\"nlp.pipe_names before adding contextualSpellCheck: {nlp.pipe_names}\")\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "print(f\"\\nnlp.pipe_names after  adding contextualSpellCheck: {nlp.pipe_names}\")\n",
    "doc = nlp(\"Income was $9.4 milion compared to the prior year of $2.7 milion\")\n",
    "print(f\"\\ncontextualSpellCheck added as extension: {doc._.contextual_spellCheck}\")\n",
    "print(f\"\\nspell check performed: {doc._.performed_spellCheck}\")\n",
    "print(f\"\\nsuggestions: {doc._.suggestions_spellCheck}\")\n",
    "print(f\"\\nspell check output (str): {doc._.outcome_spellCheck}\")\n",
    "print(f\"\\nspell check score: {doc._.score_spellCheck}\")\n",
    "print(\"\\nTokens from spacy doc:\")\n",
    "for token in doc:\n",
    "    print(f\"    {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f863717",
   "metadata": {},
   "source": [
    "### Add contextualSpellCheck to spaCy pipeline manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5daba859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp.pipe_names before adding contextualSpellCheck: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "\n",
      "nlp.pipe_names after adding contextualSpellCheck: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'contextual spellchecker']\n",
      "\n",
      "contextualSpellCheck added as extension: True\n",
      "\n",
      "spell check performed: True\n",
      "\n",
      "suggestions: {milion: 'million', milion: 'million'}\n",
      "\n",
      "spell check output (str): Income was $9.4 million compared to the prior year of $2.7 million\n",
      "\n",
      "spell check score: {milion: [('million', 0.42275), (',', 0.23874), ('mi', 0.13952), ('billion', 0.10526), ('trillion', 0.01076), ('%', 0.00577), ('Mi', 0.00542), ('##M', 0.00512), ('.', 0.00276), ('Million', 0.00268)], milion: [('.', 0.99228), (';', 0.00648), ('!', 0.00054), ('million', 0.0003), ('billion', 0.00014), ('?', 5e-05), ('...', 2e-05), ('|', 2e-05), ('%', 1e-05), (',', 1e-05)]}\n",
      "\n",
      "Tokens from spacy doc:\n",
      "    Income\n",
      "    was\n",
      "    $\n",
      "    9.4\n",
      "    milion\n",
      "    compared\n",
      "    to\n",
      "    the\n",
      "    prior\n",
      "    year\n",
      "    of\n",
      "    $\n",
      "    2.7\n",
      "    milion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import contextualSpellCheck\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(f\"nlp.pipe_names before adding contextualSpellCheck: {nlp.pipe_names}\")\n",
    "nlp.add_pipe(\"contextual spellchecker\")\n",
    "print(f\"\\nnlp.pipe_names after adding contextualSpellCheck: {nlp.pipe_names}\")\n",
    "doc = nlp(\"Income was $9.4 milion compared to the prior year of $2.7 milion\")\n",
    "print(f\"\\ncontextualSpellCheck added as extension: {doc._.contextual_spellCheck}\")\n",
    "print(f\"\\nspell check performed: {doc._.performed_spellCheck}\")\n",
    "print(f\"\\nsuggestions: {doc._.suggestions_spellCheck}\")\n",
    "print(f\"\\nspell check output (str): {doc._.outcome_spellCheck}\")\n",
    "print(f\"\\nspell check score: {doc._.score_spellCheck}\")\n",
    "print(\"\\nTokens from spacy doc:\")\n",
    "for token in doc:\n",
    "    print(f\"    {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07001f46",
   "metadata": {},
   "source": [
    "## autocorrect\n",
    "This package takes in raw text and returns a string. The documentation is almost nonexistant but it is straightforward to use.\n",
    "\n",
    "See also:\n",
    "\n",
    "https://github.com/filyp/autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06808e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "I'm not sleepy and there is no place I'm going to.\n"
     ]
    }
   ],
   "source": [
    "import autocorrect\n",
    "spell = autocorrect.Speller()\n",
    "text = \"I'm not sleapy and tehre is no place I'm giong to.\"\n",
    "corrected_text = spell(text)\n",
    "print(type(corrected_text))\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860f5ce",
   "metadata": {},
   "source": [
    "## textblob\n",
    "This package can perform a number of NLP tasks including:\n",
    "- POS tagging\n",
    "- Noun phrase extraction\n",
    "- Sentiment analysis\n",
    "- Tokenization\n",
    "- Word inflection and lemmatization\n",
    "- WordNet integration\n",
    "- WordLists\n",
    "- Spelling correction\n",
    "- Word and noun phrase frequencies\n",
    "- Parsing\n",
    "- n-grams\n",
    "- Start and end indices of sentences\n",
    "\n",
    "The initial text string is converted into a textblob object and would need to be converted back to a string to pass into spaCy.\n",
    "\n",
    "See also:\n",
    "\n",
    "https://github.com/sloria/textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fabe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'textblob.blob.TextBlob'>\n",
      "A sentence to check!\n",
      "A sentence to check!\n",
      "A sentence to check!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Sentence\n",
    "text = \"A sentencee to checkk!\"\n",
    "# using a TextBlob\n",
    "blob = TextBlob(text)\n",
    "result = blob.correct()\n",
    "print(type(result))\n",
    "print(result)\n",
    "print(str(result))\n",
    "# cast to string for use in spaCy\n",
    "result2 = str(result)\n",
    "# using a Sentence\n",
    "sentence = Sentence(text)\n",
    "print(str(sentence.correct()))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
